import { useState, useCallback } from 'react';
import { useChatStore } from '@/lib/store';
import { callGeminiAPIStream, callCozeAPIStream, callDeepSeekAPIStream, callGemini3APIStream } from '@/lib/api';
import { getModelById } from '@/config/models';

export function useChat() {
  const {
    currentSession,
    addMessage,
    updateMessage,
    setLoading,
    setError,
    selectedModelId
  } = useChatStore();

  const [streamingMessageId, setStreamingMessageId] = useState<string | null>(null);

  const sendMessage = useCallback(async (content: string, files?: File[]) => {
    if (!currentSession || (!content.trim() && (!files || files.length === 0))) return;

    const sessionId = currentSession.id;
    setError(null);
    setLoading(true);

    try {
      // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
      addMessage(sessionId, {
        role: 'user',
        content: content.trim()
      });

      // åˆ›å»ºAIæ¶ˆæ¯å ä½ç¬¦
      addMessage(sessionId, {
        role: 'assistant',
        content: '',
        isStreaming: true
      });

      // è·å–åˆšåˆ›å»ºçš„AIæ¶ˆæ¯ID
      const updatedSessionAfterAI = useChatStore.getState().sessions.find(s => s.id === sessionId);
      if (!updatedSessionAfterAI) {
        throw new Error('ä¼šè¯ä¸å­˜åœ¨');
      }
      const aiMessageId = updatedSessionAfterAI.messages[updatedSessionAfterAI.messages.length - 1].id;

      // è·å–ç”¨äºAPIè°ƒç”¨çš„æ¶ˆæ¯ï¼ˆä¸åŒ…æ‹¬æ­£åœ¨æµå¼ä¼ è¾“çš„AIæ¶ˆæ¯ï¼‰
      const messages = updatedSessionAfterAI.messages.slice(0, -1);
      setStreamingMessageId(aiMessageId);

      // è·å–å½“å‰æ¨¡å‹é…ç½®
      const currentModel = getModelById(selectedModelId);
      const isCozeModel = currentModel?.provider === 'coze';
      const isDeepSeekModel = currentModel?.provider === 'deepseek';
      const isGemini3Model = currentModel?.provider === 'gemini3';

      // æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©APIè°ƒç”¨æ–¹å¼
      let apiCall;
      if (isCozeModel) {
        apiCall = callCozeAPIStream;
      } else if (isDeepSeekModel) {
        apiCall = callDeepSeekAPIStream;
      } else if (isGemini3Model) {
        apiCall = callGemini3APIStream;
      } else {
        apiCall = callGeminiAPIStream;
      }

      // è°ƒç”¨APIè·å–æµå¼å“åº”
      if (isDeepSeekModel || isGemini3Model) {
        // DeepSeek APIä¸æ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼Œåªä¼ é€’åŸºæœ¬å‚æ•°
        await apiCall(
          messages,
          selectedModelId,
          // onChunk: æ›´æ–°æ¶ˆæ¯å†…å®¹
          (chunk: string) => {
            console.log('ğŸ¯ useChatæ”¶åˆ°chunk:', chunk);
            console.log('ğŸ¯ æ›´æ–°æ¶ˆæ¯ID:', aiMessageId, 'ä¼šè¯ID:', sessionId);
            updateMessage(sessionId, aiMessageId, {
              content: chunk,
              isStreaming: true
            });
            console.log('ğŸ¯ æ¶ˆæ¯æ›´æ–°å®Œæˆ');
          },
          // onComplete: å®Œæˆæµå¼å“åº”
          () => {
            updateMessage(sessionId, aiMessageId, {
              isStreaming: false
            });
            setStreamingMessageId(null);
            setLoading(false);
          },
          // onError: å¤„ç†é”™è¯¯
          (error: Error) => {
            console.error('èŠå¤©é”™è¯¯:', error);
            setError(error.message);

            // æ›´æ–°æ¶ˆæ¯æ˜¾ç¤ºé”™è¯¯
            updateMessage(sessionId, aiMessageId, {
              content: `æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯: ${error.message}`,
              isStreaming: false
            });

            setStreamingMessageId(null);
            setLoading(false);
          }
        );
      } else {
        // Cozeå’ŒGemini APIæ”¯æŒæ–‡ä»¶ä¸Šä¼ 
        await apiCall(
          messages,
          selectedModelId,
          // onChunk: æ›´æ–°æ¶ˆæ¯å†…å®¹
          (chunk: string) => {
            console.log('ğŸ¯ useChatæ”¶åˆ°chunk:', chunk);
            console.log('ğŸ¯ æ›´æ–°æ¶ˆæ¯ID:', aiMessageId, 'ä¼šè¯ID:', sessionId);
            updateMessage(sessionId, aiMessageId, {
              content: chunk,
              isStreaming: true
            });
            console.log('ğŸ¯ æ¶ˆæ¯æ›´æ–°å®Œæˆ');
          },
          // onComplete: å®Œæˆæµå¼å“åº”
          () => {
            updateMessage(sessionId, aiMessageId, {
              isStreaming: false
            });
            setStreamingMessageId(null);
            setLoading(false);
          },
          // onError: å¤„ç†é”™è¯¯
          (error: Error) => {
            console.error('èŠå¤©é”™è¯¯:', error);
            setError(error.message);

            // æ›´æ–°æ¶ˆæ¯æ˜¾ç¤ºé”™è¯¯
            updateMessage(sessionId, aiMessageId, {
              content: `æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯: ${error.message}`,
              isStreaming: false
            });

            setStreamingMessageId(null);
            setLoading(false);
          },
          // ä¼ é€’æ–‡ä»¶å‚æ•°
          files
        );
      }

    } catch (error) {
      console.error('å‘é€æ¶ˆæ¯é”™è¯¯:', error);
      const errorMessage = error instanceof Error ? error.message : 'å‘é€æ¶ˆæ¯å¤±è´¥';
      setError(errorMessage);
      setLoading(false);
      setStreamingMessageId(null);
    }
  }, [currentSession, selectedModelId, addMessage, updateMessage, setLoading, setError]);

  const stopGeneration = useCallback(() => {
    if (streamingMessageId && currentSession) {
      updateMessage(currentSession.id, streamingMessageId, {
        isStreaming: false
      });
      setStreamingMessageId(null);
      setLoading(false);
    }
  }, [streamingMessageId, currentSession, updateMessage, setLoading]);

  const regenerateLastMessage = useCallback(async () => {
    if (!currentSession || currentSession.messages.length < 2) return;

    const sessionId = currentSession.id;
    const messages = currentSession.messages;
    const lastUserMessage = messages[messages.length - 2];
    const lastAiMessage = messages[messages.length - 1];

    if (lastUserMessage.role !== 'user' || lastAiMessage.role !== 'assistant') {
      return;
    }

    // é‡æ–°ç”Ÿæˆæœ€åä¸€æ¡AIæ¶ˆæ¯
    setError(null);
    setLoading(true);
    setStreamingMessageId(lastAiMessage.id);

    try {
      // é‡ç½®AIæ¶ˆæ¯å†…å®¹
      updateMessage(sessionId, lastAiMessage.id, {
        content: '',
        isStreaming: true
      });

      // è·å–é™¤äº†æœ€åä¸€æ¡AIæ¶ˆæ¯ä¹‹å¤–çš„æ‰€æœ‰æ¶ˆæ¯
      const messagesForAPI = messages.slice(0, -1);

      await callGeminiAPIStream(
        messagesForAPI,
        selectedModelId,
        // onChunk
        (chunk: string) => {
          updateMessage(sessionId, lastAiMessage.id, {
            content: chunk,
            isStreaming: true
          });
        },
        // onComplete
        () => {
          updateMessage(sessionId, lastAiMessage.id, {
            isStreaming: false
          });
          setStreamingMessageId(null);
          setLoading(false);
        },
        // onError
        (error: Error) => {
          console.error('é‡æ–°ç”Ÿæˆé”™è¯¯:', error);
          setError(error.message);
          
          updateMessage(sessionId, lastAiMessage.id, {
            content: `æŠ±æ­‰ï¼Œé‡æ–°ç”Ÿæˆå¤±è´¥: ${error.message}`,
            isStreaming: false
          });
          
          setStreamingMessageId(null);
          setLoading(false);
        }
      );

    } catch (error) {
      console.error('é‡æ–°ç”Ÿæˆæ¶ˆæ¯é”™è¯¯:', error);
      const errorMessage = error instanceof Error ? error.message : 'é‡æ–°ç”Ÿæˆå¤±è´¥';
      setError(errorMessage);
      setLoading(false);
      setStreamingMessageId(null);
    }
  }, [currentSession, selectedModelId, updateMessage, setLoading, setError]);

  return {
    sendMessage,
    stopGeneration,
    regenerateLastMessage,
    isStreaming: streamingMessageId !== null
  };
}
